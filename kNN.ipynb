{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, feature, color, data\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = './data/seg_train/seg_train/'\n",
    "test_img_path = './data/seg_test/seg_test/'\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "labels=['Buildings','Forest', 'Glacier','Mountain','Sea','Street']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts Histogram of Oriented Gradients of one image used for classification\n",
    "def get_hog(jpeg_path):\n",
    "    jpg = cv2.imread(jpeg_path)\n",
    "    jpg = cv2.resize(jpg,(150,150))\n",
    "    gray= cv2.cvtColor(jpg,cv2.COLOR_BGR2GRAY)\n",
    "    hog = feature.hog(gray)/255.0\n",
    "    return hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetches all images from the data folder and gets hog for each file aswell as saves the labels in different array\n",
    "#Works with both train and test data\n",
    "def jpeg_to_array (scene_type, img_root_path, data_type):\n",
    "    scene_path = os.path.join(img_root_path,scene_type.lower())\n",
    "    print('Loading ' + data_type +' images for scene type '+scene_type)\n",
    "    for img in os.listdir(scene_path):\n",
    "        img_path = os.path.join(scene_path,img)\n",
    "        #Check if the path leads to an image\n",
    "        if img_path.endswith('.jpg'):\n",
    "            #Check if it is training or testing data and puts it in the right array\n",
    "            if(data_type == 'Training'):\n",
    "                X_train.append(get_hog(img_path))\n",
    "                y_train.append(labels.index(str(scene_type)))\n",
    "            if(data_type =='Testing'):\n",
    "                X_test.append(get_hog(img_path))\n",
    "                y_test.append(labels.index(str(scene_type)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training images for scene type Buildings\n",
      "Loading Training images for scene type Forest\n",
      "Loading Training images for scene type Glacier\n",
      "Loading Training images for scene type Mountain\n",
      "Loading Training images for scene type Sea\n",
      "Loading Training images for scene type Street\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[jpeg_to_array(scene,train_img_path,'Training')for scene in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Testing images for scene type Buildings\n",
      "Loading Testing images for scene type Forest\n",
      "Loading Testing images for scene type Glacier\n",
      "Loading Testing images for scene type Mountain\n",
      "Loading Testing images for scene type Sea\n",
      "Loading Testing images for scene type Street\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[jpeg_to_array(scene,test_img_path,'Testing')for scene in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model and fit it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with n= 4\n",
      "Done with n= 5\n",
      "Done with n= 6\n",
      "Done with n= 7\n",
      "Done with n= 8\n",
      "Done with n= 9\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for i in range(4,10):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i, weights='distance', p=1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    pred.append(neigh.predict(X_test))\n",
    "    print('Done with n= ' + str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187 110  16  30  73  21]\n",
      " [  0 465   0   4   5   0]\n",
      " [  2  51 128 128 244   0]\n",
      " [  2  19  34 220 250   0]\n",
      " [  3  12   9  27 456   3]\n",
      " [ 35 237  13  22  48 146]]\n",
      "0.534\n",
      "[[186 117  18  32  69  15]\n",
      " [  0 463   0   4   7   0]\n",
      " [  2  55 106 132 257   1]\n",
      " [  0  22  28 212 263   0]\n",
      " [  3  11   6  20 468   2]\n",
      " [ 31 250  10  20  54 136]]\n",
      "0.5236666666666666\n",
      "[[185 117  15  38  68  14]\n",
      " [  0 464   0   4   6   0]\n",
      " [  2  55 116 123 257   0]\n",
      " [  0  20  29 210 266   0]\n",
      " [  3  14   4  21 466   2]\n",
      " [ 31 247  12  17  56 138]]\n",
      "0.5263333333333333\n",
      "[[177 120  17  36  72  15]\n",
      " [  0 465   0   4   5   0]\n",
      " [  1  56 114 114 268   0]\n",
      " [  0  19  21 217 268   0]\n",
      " [  3  14   4  22 465   2]\n",
      " [ 20 262   9  17  56 137]]\n",
      "0.525\n",
      "[[174 126  16  37  70  14]\n",
      " [  0 464   0   4   6   0]\n",
      " [  1  56 114 116 266   0]\n",
      " [  0  19  25 210 271   0]\n",
      " [  3  15   2  17 471   2]\n",
      " [ 22 262   8  20  53 136]]\n",
      "0.523\n",
      "[[172 129  16  38  68  14]\n",
      " [  0 464   0   4   6   0]\n",
      " [  1  58 105 113 276   0]\n",
      " [  0  21  19 211 274   0]\n",
      " [  3  15   2  15 473   2]\n",
      " [ 22 273   9  17  53 127]]\n",
      "0.5173333333333333\n"
     ]
    }
   ],
   "source": [
    "for preds in pred:\n",
    "    print(confusion_matrix(y_test,preds))\n",
    "    print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
