{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, feature, color, data\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = './data/seg_train/seg_train/'\n",
    "test_img_path = './data/seg_test/seg_test/'\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "labels=['Buildings','Forest', 'Glacier','Mountain','Sea','Street']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts Histogram of Oriented Gradients of one image used for classification\n",
    "def get_hog(jpeg_path):\n",
    "    jpg = cv2.imread(jpeg_path)\n",
    "    jpg = cv2.resize(jpg,(150,150))\n",
    "    hog = feature.hog(jpg)/255.0\n",
    "    return hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetches all images from the data folder and gets hog for each file aswell as saves the labels in different array\n",
    "#Works with both train and test data\n",
    "def jpeg_to_array (scene_type, img_root_path, data_type):\n",
    "    scene_path = os.path.join(img_root_path,scene_type.lower())\n",
    "    print('Loading ' + data_type +' images for scene type '+scene_type)\n",
    "    for img in os.listdir(scene_path):\n",
    "        img_path = os.path.join(scene_path,img)\n",
    "        #Check if the path leads to an image\n",
    "        if img_path.endswith('.jpg'):\n",
    "            #Check if it is training or testing data and puts it in the right array\n",
    "            if(data_type == 'Training'):\n",
    "                X_train.append(get_hog(img_path))\n",
    "                y_train.append(labels.index(str(scene_type)))\n",
    "            if(data_type =='Testing'):\n",
    "                X_test.append(get_hog(img_path))\n",
    "                y_test.append(labels.index(str(scene_type)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training images for scene type Buildings\n",
      "Loading Training images for scene type Forest\n",
      "Loading Training images for scene type Glacier\n",
      "Loading Training images for scene type Mountain\n",
      "Loading Training images for scene type Sea\n",
      "Loading Training images for scene type Street\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[jpeg_to_array(scene,train_img_path,'Training')for scene in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Testing images for scene type Buildings\n",
      "Loading Testing images for scene type Forest\n",
      "Loading Testing images for scene type Glacier\n",
      "Loading Testing images for scene type Mountain\n",
      "Loading Testing images for scene type Sea\n",
      "Loading Testing images for scene type Street\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[jpeg_to_array(scene,test_img_path,'Testing')for scene in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with n= 11\n",
      "Done with n= 12\n",
      "Done with n= 13\n",
      "Done with n= 14\n",
      "Done with n= 15\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for i in range(11,16):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i, p=1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    pred.append(neigh.predict(X_test))\n",
    "    print('Done with n= ' + str(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[174 136  13  27  76  11]\n",
      " [  0 466   0   4   4   0]\n",
      " [  1  74 113 112 253   0]\n",
      " [  0  28  25 190 282   0]\n",
      " [  3  16   5  14 470   2]\n",
      " [ 28 290   9  11  46 117]]\n",
      "0.51\n",
      "[[174 140  12  33  69   9]\n",
      " [  0 466   0   4   4   0]\n",
      " [  1  81 109 107 255   0]\n",
      " [  0  27  22 199 277   0]\n",
      " [  3  16   2  17 470   2]\n",
      " [ 25 286  10  12  46 122]]\n",
      "0.5133333333333333\n",
      "[[168 143  13  30  71  12]\n",
      " [  0 466   0   4   4   0]\n",
      " [  1  78 104 106 264   0]\n",
      " [  0  26  18 193 288   0]\n",
      " [  3  17   2  11 475   2]\n",
      " [ 21 289   9  11  48 123]]\n",
      "0.5096666666666667\n",
      "[[166 146  12  29  73  11]\n",
      " [  0 466   0   3   5   0]\n",
      " [  1  82 100 108 262   0]\n",
      " [  0  27  18 194 286   0]\n",
      " [  3  18   2  13 472   2]\n",
      " [ 22 291  10  14  46 118]]\n",
      "0.5053333333333333\n",
      "[[165 146  12  30  73  11]\n",
      " [  0 467   0   3   4   0]\n",
      " [  1  84 102 105 261   0]\n",
      " [  0  28  18 187 292   0]\n",
      " [  3  18   3  12 472   2]\n",
      " [ 24 293   9  12  48 115]]\n",
      "0.5026666666666667\n"
     ]
    }
   ],
   "source": [
    "for preds in pred:\n",
    "    print(confusion_matrix(y_test,preds))\n",
    "    print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
